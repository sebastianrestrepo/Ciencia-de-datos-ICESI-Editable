{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naïve Bayes: Iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear un modelo de clasificación con Naïve Bayes para el dataset de Iris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las librerías que vamos a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #operaciones matriciales y con vectores\n",
    "import pandas as pd #tratamiento de datos\n",
    "#import matplotlib.pyplot as plt #gráficos\n",
    "from sklearn import naive_bayes, neighbors, datasets, metrics\n",
    "from sklearn.model_selection import train_test_split #metodo de particionamiento de datasets para evaluación\n",
    "from sklearn.model_selection import cross_val_score, cross_validate #método para evaluar varios particionamientos de C-V\n",
    "#from sklearn.model_selection import KFold, StratifiedKFold, RepeatedKFold, LeaveOneOut #Iteradores de C-V\n",
    "#import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos y creamos una sola estructura con todos los datos para poder visualizarlos más fácilmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3. , 1.4, 0.2, 0. ],\n",
       "       [4.7, 3.2, 1.3, 0.2, 0. ],\n",
       "       [4.6, 3.1, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.6, 1.4, 0.2, 0. ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "data = np.concatenate((X, np.expand_dims(y, axis=1)), axis = 1)\n",
    "data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación a partir de Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a utilizar un clasificador Naïve Bayes que supone una distribución Gaussiana de los datos numéricos, ya que los valores de las variables independientes son continuos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = naive_bayes.GaussianNB()\n",
    "modeloGNB = gnb.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos los patrones que encuentra el clasificador con respecto a las clases (conteo, probabilidades a priori) y los parámetros de sus distribuciones (promedios y desviaciones estándar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50., 50., 50.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeloGNB.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33333333, 0.33333333, 0.33333333])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeloGNB.class_prior_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.006, 3.428, 1.462, 0.246],\n",
       "       [5.936, 2.77 , 4.26 , 1.326],\n",
       "       [6.588, 2.974, 5.552, 2.026]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeloGNB.theta_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.121764, 0.142276, 0.029504, 0.011264],\n",
       "       [0.261104, 0.0965  , 0.2164  , 0.038324],\n",
       "       [0.396256, 0.101924, 0.298496, 0.073924]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeloGNB.sigma_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos como nos va sobre el mismo dataset de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = modeloGNB.predict(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo de Naïve Bayes se equivocó en 6 de los 150 registros que componen el dataset original\n"
     ]
    }
   ],
   "source": [
    "print(\"El modelo de Naïve Bayes se equivocó en %d de los %d registros que componen el dataset original\"\n",
    "      % ((y != y_pred).sum(), iris.data.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación con K-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor modelo K-NN que habíamos encontrado previamente consideraba un parámetro K=3.\n",
    "Vamos a compararlos con respecto al accuracy, siguiendo un protocolo de cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 0.88888889, 1.        , 1.        ,\n",
       "       1.        , 0.77777778, 0.88888889, 1.        , 1.        ,\n",
       "       1.        , 0.83333333, 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "knn_exactitudes = cross_val_score(knn, X, y, cv=20, scoring='accuracy')\n",
    "knn_exactitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que con KNN los scores de las 20 iteraciones del CV dan resultados entre 77.7% y 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88888889, 1.        , 0.88888889, 1.        , 1.        ,\n",
       "       1.        , 0.77777778, 1.        , 1.        , 0.88888889,\n",
       "       1.        , 0.83333333, 0.83333333, 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_exactitudes = cross_val_score(gnb, X, y, cv=20, scoring='accuracy')\n",
    "gnb_exactitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que con Naïve Bayes los scores de las 20 iteraciones del CV dan resultados entre 77.7% y 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos obtener un intervalo de confianza del 95% para tener una idea más clara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN. Exactitudes: 0.97 (+/- 0.13)\n",
      "GNB. Exactitudes: 0.96 (+/- 0.14)\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN. Exactitudes: %0.2f (+/- %0.2f)\" % (knn_exactitudes.mean(), knn_exactitudes.std() * 2))\n",
    "print(\"GNB. Exactitudes: %0.2f (+/- %0.2f)\" % (gnb_exactitudes.mean(), gnb_exactitudes.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que los dos modelos son bastante parecidos para el dataset iris, con una ligera ventaja para el modelo KNN. No siempre va a ser igual. Hay que tener en cuenta que este es un dataset muy sencillo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
